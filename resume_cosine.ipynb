{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "095a6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f2b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e97a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab825761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9498b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "# Docx resume\n",
    "import docx2txt\n",
    "\n",
    "#Wordcloud\n",
    "import re\n",
    "import operator\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "#from wordcloud import WordCloud\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6714ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf_resume(pdf_doc):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    \n",
    "    with open(pdf_doc, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, \n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    "            \n",
    "        text = fake_file_handle.getvalue()\n",
    "    \n",
    "    # close open handles\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    "    \n",
    "    if text:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1606fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_word_resume(word_doc):\n",
    "    #resume = docx2txt.process(word_doc)\n",
    "    #text = ''.join(resume)\n",
    "    resume = docx2txt.process(word_doc)\n",
    "    resume = str(resume)\n",
    "    #print(resume)\n",
    "    text =  ''.join(resume)\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    \n",
    "    if text:\n",
    "        return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "572dd150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_decsription(jd):\n",
    "    ''' a function to create a word cloud based on the input text parameter'''\n",
    "    ## Clean the Text\n",
    "    # Lower\n",
    "    clean_jd = jd.lower()\n",
    "    # remove punctuation\n",
    "    clean_jd = re.sub(r'[^\\w\\s]', '', clean_jd)\n",
    "    # remove trailing spaces\n",
    "    clean_jd = clean_jd.strip()\n",
    "    # remove numbers\n",
    "    clean_jd = re.sub('[0-9]+', '', clean_jd)\n",
    "    # tokenize \n",
    "    clean_jd = word_tokenize(clean_jd)\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    #stop.extend([\"AT_USER\",\"URL\",\"rt\",\"corona\",\"coronavirus\",\"covid\",\"amp\",\"new\",\"th\",\"along\",\"icai\",\"would\",\"today\",\"asks\"])\n",
    "    clean_jd = [w for w in clean_jd if not w in stop] \n",
    "    \n",
    "    return(clean_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab972ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "602f21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resume_score(text):\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    #Print the similarity scores\n",
    "    print(\"\\nSimilarity Scores:\")\n",
    "    #print(cosine_similarity(count_matrix))\n",
    "    #get the match percentage\n",
    "    matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "    matchPercentage = round(matchPercentage, 2) # round to two decimal\n",
    "    print(\"Your resume matches about \"+ str(matchPercentage)+ \"% of the job description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dec4dfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Extension: word\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_resume.docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     resume \u001b[38;5;241m=\u001b[39m read_pdf_resume(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResume_OindrilaSen.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     resume \u001b[38;5;241m=\u001b[39m \u001b[43mread_word_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_resume.docx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m job_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnter the Job Description: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m clean_jd \u001b[38;5;241m=\u001b[39m clean_job_decsription(job_description)\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mread_word_resume\u001b[0;34m(word_doc)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_word_resume\u001b[39m(word_doc):\n\u001b[0;32m----> 2\u001b[0m     resume \u001b[38;5;241m=\u001b[39m \u001b[43mdocx2txt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_doc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     resume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(resume)\n\u001b[1;32m      4\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(resume)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/docx2txt/docx2txt.py:76\u001b[0m, in \u001b[0;36mprocess\u001b[0;34m(docx, img_dir)\u001b[0m\n\u001b[1;32m     73\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# unzip the docx in memory\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m zipf \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m filelist \u001b[38;5;241m=\u001b[39m zipf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# get header text\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# there can be 3 header files in the zip\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/zipfile.py:1248\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1248\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_resume.docx'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    extn = input(\"Enter File Extension: \")\n",
    "    if extn == \"pdf\":\n",
    "        resume = read_pdf_resume('Resume_OindrilaSen.pdf')\n",
    "    else:\n",
    "        resume = read_word_resume('test_resume.docx')\n",
    "    \n",
    "    job_description = input(\"\\nEnter the Job Description: \")\n",
    "\n",
    "    clean_jd = clean_job_decsription(job_description)\n",
    "    create_word_cloud(clean_jd)\n",
    "    \n",
    "    text = [resume, job_description]\n",
    "\n",
    "    get_resume_score(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "538e0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Extension: pdf\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Resume_OindrilaSen.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print(extn)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m     resume \u001b[38;5;241m=\u001b[39m \u001b[43mread_pdf_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResume_OindrilaSen.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     resume \u001b[38;5;241m=\u001b[39m read_word_resume(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_resume.docx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mread_pdf_resume\u001b[0;34m(pdf_doc)\u001b[0m\n\u001b[1;32m      4\u001b[0m converter \u001b[38;5;241m=\u001b[39m TextConverter(resource_manager, fake_file_handle)\n\u001b[1;32m      5\u001b[0m page_interpreter \u001b[38;5;241m=\u001b[39m PDFPageInterpreter(resource_manager, converter)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpdf_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m PDFPage\u001b[38;5;241m.\u001b[39mget_pages(fh, \n\u001b[1;32m      9\u001b[0m                                   caching\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                                   check_extractable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     11\u001b[0m         page_interpreter\u001b[38;5;241m.\u001b[39mprocess_page(page)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Resume_OindrilaSen.pdf'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    extn = input(\"Enter File Extension: \")\n",
    "    #print(extn)\n",
    "    if extn == \"pdf\":\n",
    "        resume = read_pdf_resume('Resume_OindrilaSen.pdf')\n",
    "    else:\n",
    "        resume = read_word_resume('test_resume.docx')\n",
    "    \n",
    "    job_description = input(\"\\nEnter the Job Description: \")\n",
    "\n",
    "    ## Get a Keywords Cloud\n",
    "    clean_jd = clean_job_decsription(job_description)\n",
    "    create_word_cloud(clean_jd)\n",
    "    \n",
    "    text = [resume, job_description]\n",
    "    \n",
    "    ## Get a Match\n",
    "    get_resume_score(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c61d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
